{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade \\\n",
    "    pip \\\n",
    "    python-dotenv \\\n",
    "    datasets \\\n",
    "    accelerate \\\n",
    "    peft \\\n",
    "    bitsandbytes \\\n",
    "    transformers \\\n",
    "    trl \\\n",
    "    sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    "    TrainingArguments,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n",
    "\n",
    "from trl import ORPOConfig, ORPOTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./gpt2_tagalog\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the pad token to be the same as the eos token\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and analyze the data for finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incomplete Sentence</th>\n",
       "      <th>Suggestions</th>\n",
       "      <th>Rejected Suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kumain ako ng ma</td>\n",
       "      <td>['manok', 'mangga', 'mais']</td>\n",
       "      <td>['mataas', 'marahas', 'marunong']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maglalaro tayo ng b</td>\n",
       "      <td>['bola', 'basketball', 'badminton']</td>\n",
       "      <td>['bahay', 'bata', 'buwan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ang ganda ng a</td>\n",
       "      <td>['araw', 'awit', 'arte']</td>\n",
       "      <td>['alis', 'aso', 'anak']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pumunta kami sa ba</td>\n",
       "      <td>['bakuran', 'bayan', 'bahay']</td>\n",
       "      <td>['bagyo', 'baril', 'bakasyon']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maglalaro tayo ng b</td>\n",
       "      <td>['basketball', 'bola', 'badminton']</td>\n",
       "      <td>['buwan', 'bahay', 'bata']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Incomplete Sentence                          Suggestions  \\\n",
       "0     Kumain ako ng ma          ['manok', 'mangga', 'mais']   \n",
       "1  Maglalaro tayo ng b  ['bola', 'basketball', 'badminton']   \n",
       "2       Ang ganda ng a             ['araw', 'awit', 'arte']   \n",
       "3   Pumunta kami sa ba        ['bakuran', 'bayan', 'bahay']   \n",
       "4  Maglalaro tayo ng b  ['basketball', 'bola', 'badminton']   \n",
       "\n",
       "                Rejected Suggestions  \n",
       "0  ['mataas', 'marahas', 'marunong']  \n",
       "1         ['bahay', 'bata', 'buwan']  \n",
       "2            ['alis', 'aso', 'anak']  \n",
       "3     ['bagyo', 'baril', 'bakasyon']  \n",
       "4         ['buwan', 'bahay', 'bata']  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tagalog_keyboard_data = pd.read_csv(\"/teamspace/studios/this_studio/tagalog-keyboard-data.csv\")\n",
    "tagalog_keyboard_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kumain ako ng ma</td>\n",
       "      <td>['manok', 'mangga', 'mais']</td>\n",
       "      <td>['mataas', 'marahas', 'marunong']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maglalaro tayo ng b</td>\n",
       "      <td>['bola', 'basketball', 'badminton']</td>\n",
       "      <td>['bahay', 'bata', 'buwan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ang ganda ng a</td>\n",
       "      <td>['araw', 'awit', 'arte']</td>\n",
       "      <td>['alis', 'aso', 'anak']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pumunta kami sa ba</td>\n",
       "      <td>['bakuran', 'bayan', 'bahay']</td>\n",
       "      <td>['bagyo', 'baril', 'bakasyon']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maglalaro tayo ng b</td>\n",
       "      <td>['basketball', 'bola', 'badminton']</td>\n",
       "      <td>['buwan', 'bahay', 'bata']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                prompt                               chosen  \\\n",
       "0     Kumain ako ng ma          ['manok', 'mangga', 'mais']   \n",
       "1  Maglalaro tayo ng b  ['bola', 'basketball', 'badminton']   \n",
       "2       Ang ganda ng a             ['araw', 'awit', 'arte']   \n",
       "3   Pumunta kami sa ba        ['bakuran', 'bayan', 'bahay']   \n",
       "4  Maglalaro tayo ng b  ['basketball', 'bola', 'badminton']   \n",
       "\n",
       "                            rejected  \n",
       "0  ['mataas', 'marahas', 'marunong']  \n",
       "1         ['bahay', 'bata', 'buwan']  \n",
       "2            ['alis', 'aso', 'anak']  \n",
       "3     ['bagyo', 'baril', 'bakasyon']  \n",
       "4         ['buwan', 'bahay', 'bata']  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns\n",
    "tagalog_keyboard_data = tagalog_keyboard_data.rename(columns={\n",
    "    'Incomplete Sentence': 'prompt',\n",
    "    'Suggestions': 'chosen',\n",
    "    'Rejected Suggestions': 'rejected'\n",
    "})\n",
    "tagalog_keyboard_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chosen', 'rejected', 'prompt'],\n",
       "    num_rows: 100000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "# Create a Hugging Face Dataset from the DataFrame\n",
    "dataset = Dataset.from_pandas(tagalog_keyboard_data[['chosen', 'rejected', 'prompt']])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chosen', 'rejected', 'prompt'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter the dataset to 1000 examples\n",
    "dataset = dataset.shuffle(seed=42).select(range(1000))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chosen': \"['basketball', 'bola', 'badminton']\",\n",
       " 'rejected': \"['buwan', 'bata', 'bahay']\",\n",
       " 'prompt': 'Maglalaro tayo ng b'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def format_chat_template(row):\n",
    "    # Parse the Chosen and Rejected columns which are string representations of lists\n",
    "    chosen_list = ast.literal_eval(row[\"chosen\"])  # Convert string to list of words\n",
    "    rejected_list = ast.literal_eval(row[\"rejected\"])  # Convert string to list of words\n",
    "\n",
    "    # Format the \"chosen\" response as a string with <|user|> and <|assistant|> tokens\n",
    "    chosen_response = f\"<|user|>\\n    {row['prompt']}\\n<|assistant|>\\n    {chosen_list}\"\n",
    "\n",
    "    # Format the \"rejected\" response as a string with <|user|> and <|assistant|> tokens\n",
    "    rejected_response = f\"<|user|>\\n    {row['prompt']}\\n<|assistant|>\\n    {rejected_list}\"\n",
    "\n",
    "    # Return the row with the same structure as the input, but formatted\n",
    "    return {\n",
    "        \"chosen\": chosen_response,  # Formatted chosen response\n",
    "        \"rejected\": rejected_response,  # Formatted rejected response\n",
    "        \"prompt\": row[\"prompt\"],  # The prompt remains unchanged\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PreTrainedTokenizerBase.apply_chat_template of GPT2TokenizerFast(name_or_path='./gpt2_tagalog', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a8c747a65948f289444af8c1047697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the formatting function\n",
    "formatted_dataset = dataset.map(format_chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chosen': \"<|user|>\\n    Maglalaro tayo ng b\\n<|assistant|>\\n    ['basketball', 'bola', 'badminton']\",\n",
       " 'rejected': \"<|user|>\\n    Maglalaro tayo ng b\\n<|assistant|>\\n    ['buwan', 'bata', 'bahay']\",\n",
       " 'prompt': 'Maglalaro tayo ng b'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['chosen', 'rejected', 'prompt'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['chosen', 'rejected', 'prompt'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data for train and test\n",
    "formatted_dataset = formatted_dataset.train_test_split(test_size=0.10)\n",
    "formatted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lm_head']\n"
     ]
    }
   ],
   "source": [
    "def find_linear_layers(model):\n",
    "    # Initialize a list to store the names of all linear layers\n",
    "    linear_layers = []\n",
    "    \n",
    "    # Iterate over all named modules in the model\n",
    "    for name, module in model.named_modules():\n",
    "        # Check if the module is of type Linear (from nn.Module)\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            # Append the name of the layer to the list\n",
    "            linear_layers.append(name)\n",
    "    \n",
    "    # Return the list of linear layer names\n",
    "    return linear_layers\n",
    "\n",
    "# Assuming 'model' is your GPT-2 model\n",
    "linear_layer_names = find_linear_layers(model)\n",
    "print(linear_layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default configs\n",
    "attn_implementation = \"eager\"\n",
    "torch_dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "orpo_args = ORPOConfig(\n",
    "    learning_rate=8e-6,\n",
    "    beta=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    max_length=1024,\n",
    "    max_prompt_length=512,\n",
    "    per_device_train_batch_size=25,\n",
    "    per_device_eval_batch_size=25,\n",
    "    gradient_accumulation_steps=1,  # Update after each mini-batch\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    num_train_epochs=10,  # Train for 10 epochs\n",
    "    eval_strategy=\"epoch\",  # Evaluate after each epoch\n",
    "    eval_steps=None,  # No need for eval_steps\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    save_steps=5,\n",
    "    output_dir=\"./tagalog-results-keybaord1\",\n",
    "    save_strategy=\"epoch\",  # Save after each epoch\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/trl/trainer/orpo_trainer.py:276: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a430d8ecf51445c49c53744351b811ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58eae0d33279437098c83b611d39ccc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a71bf078ec410a8d1b2849a5a3569d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5953c0ff684c6683c3a497ee31bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42f4f33a32b48bfa2dcfedb808a29e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7d6d63391c48bf99f27be493ffaa06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Setup ORPO Trainer\n",
    "trainer = ORPOTrainer(\n",
    "    model=model,\n",
    "    args=orpo_args,\n",
    "    train_dataset=formatted_dataset[\"train\"],\n",
    "    eval_dataset=formatted_dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [360/360 02:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Nll Loss</th>\n",
       "      <th>Log Odds Ratio</th>\n",
       "      <th>Log Odds Chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.879700</td>\n",
       "      <td>7.779092</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>145.441000</td>\n",
       "      <td>5.818000</td>\n",
       "      <td>-0.794597</td>\n",
       "      <td>-0.795654</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-7.956537</td>\n",
       "      <td>-7.945968</td>\n",
       "      <td>-2.830976</td>\n",
       "      <td>-2.860056</td>\n",
       "      <td>7.709191</td>\n",
       "      <td>-0.699010</td>\n",
       "      <td>0.010599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.547400</td>\n",
       "      <td>7.536638</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>144.509000</td>\n",
       "      <td>5.780000</td>\n",
       "      <td>-0.768216</td>\n",
       "      <td>-0.769629</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>-7.696295</td>\n",
       "      <td>-7.682160</td>\n",
       "      <td>-2.811978</td>\n",
       "      <td>-2.841185</td>\n",
       "      <td>7.467031</td>\n",
       "      <td>-0.696067</td>\n",
       "      <td>0.014171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.258800</td>\n",
       "      <td>7.269650</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>143.576000</td>\n",
       "      <td>5.743000</td>\n",
       "      <td>-0.739105</td>\n",
       "      <td>-0.740898</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>-7.408984</td>\n",
       "      <td>-7.391046</td>\n",
       "      <td>-2.787481</td>\n",
       "      <td>-2.816983</td>\n",
       "      <td>7.200354</td>\n",
       "      <td>-0.692960</td>\n",
       "      <td>0.017984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.948100</td>\n",
       "      <td>6.997256</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>143.580000</td>\n",
       "      <td>5.743000</td>\n",
       "      <td>-0.709317</td>\n",
       "      <td>-0.711464</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>-7.114639</td>\n",
       "      <td>-7.093169</td>\n",
       "      <td>-2.758066</td>\n",
       "      <td>-2.787998</td>\n",
       "      <td>6.928249</td>\n",
       "      <td>-0.690050</td>\n",
       "      <td>0.021529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.787100</td>\n",
       "      <td>6.737466</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>143.615000</td>\n",
       "      <td>5.745000</td>\n",
       "      <td>-0.680880</td>\n",
       "      <td>-0.683327</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>-6.833273</td>\n",
       "      <td>-6.808800</td>\n",
       "      <td>-2.726212</td>\n",
       "      <td>-2.756643</td>\n",
       "      <td>6.668709</td>\n",
       "      <td>-0.687570</td>\n",
       "      <td>0.024548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.521800</td>\n",
       "      <td>6.504169</td>\n",
       "      <td>0.697100</td>\n",
       "      <td>143.448000</td>\n",
       "      <td>5.738000</td>\n",
       "      <td>-0.655355</td>\n",
       "      <td>-0.658137</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>-6.581373</td>\n",
       "      <td>-6.553554</td>\n",
       "      <td>-2.694555</td>\n",
       "      <td>-2.725513</td>\n",
       "      <td>6.435651</td>\n",
       "      <td>-0.685171</td>\n",
       "      <td>0.027914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.352500</td>\n",
       "      <td>6.308774</td>\n",
       "      <td>0.697100</td>\n",
       "      <td>143.443000</td>\n",
       "      <td>5.738000</td>\n",
       "      <td>-0.633954</td>\n",
       "      <td>-0.637097</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>-6.370970</td>\n",
       "      <td>-6.339539</td>\n",
       "      <td>-2.665699</td>\n",
       "      <td>-2.697156</td>\n",
       "      <td>6.240487</td>\n",
       "      <td>-0.682872</td>\n",
       "      <td>0.031549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.077000</td>\n",
       "      <td>6.160684</td>\n",
       "      <td>0.698100</td>\n",
       "      <td>143.237000</td>\n",
       "      <td>5.729000</td>\n",
       "      <td>-0.617769</td>\n",
       "      <td>-0.621246</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>-6.212458</td>\n",
       "      <td>-6.177685</td>\n",
       "      <td>-2.642275</td>\n",
       "      <td>-2.674178</td>\n",
       "      <td>6.092593</td>\n",
       "      <td>-0.680902</td>\n",
       "      <td>0.034914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.997100</td>\n",
       "      <td>6.067751</td>\n",
       "      <td>0.700100</td>\n",
       "      <td>142.845000</td>\n",
       "      <td>5.714000</td>\n",
       "      <td>-0.607594</td>\n",
       "      <td>-0.611295</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>-6.112950</td>\n",
       "      <td>-6.075936</td>\n",
       "      <td>-2.626698</td>\n",
       "      <td>-2.658900</td>\n",
       "      <td>5.999791</td>\n",
       "      <td>-0.679603</td>\n",
       "      <td>0.037172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.129700</td>\n",
       "      <td>6.035469</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>143.975000</td>\n",
       "      <td>5.759000</td>\n",
       "      <td>-0.604063</td>\n",
       "      <td>-0.607846</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>-6.078465</td>\n",
       "      <td>-6.040627</td>\n",
       "      <td>-2.621108</td>\n",
       "      <td>-2.653420</td>\n",
       "      <td>5.967556</td>\n",
       "      <td>-0.679134</td>\n",
       "      <td>0.038002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=360, training_loss=6.874530659781562, metrics={'train_runtime': 149.7647, 'train_samples_per_second': 60.094, 'train_steps_per_second': 2.404, 'total_flos': 0.0, 'train_loss': 6.874530659781562, 'epoch': 10.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training\n",
    "# Step 1: Save the fine-tuned model\n",
    "trainer.save_model(\"./tagalog-keyboard-model1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flush the memory\n",
    "# Flush memory\n",
    "import gc\n",
    "#del trainer, model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./final-tagalog-keyboard-model1/tokenizer_config.json',\n",
       " './final-tagalog-keyboard-model1/special_tokens_map.json',\n",
       " './final-tagalog-keyboard-model1/vocab.json',\n",
       " './final-tagalog-keyboard-model1/merges.txt',\n",
       " './final-tagalog-keyboard-model1/added_tokens.json',\n",
       " './final-tagalog-keyboard-model1/tokenizer.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load your base GPT-2 model and tokenizer\n",
    "base_model_path = \"./gpt2_tagalog\"  # Path to your base GPT-2 Tagalog model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "# Set up the chat format by adding special tokens for user and assistant\n",
    "base_model, tokenizer = setup_chat_format(base_model, tokenizer)  # Set up for chat format\n",
    "\n",
    "# Step 3: Load the fine-tuned adapter model (if using PEFT or adapter)\n",
    "adapter_model_path = \"./tagalog-keyboard-model1\"  # Path to your fine-tuned model\n",
    "adapter_model = PeftModel.from_pretrained(base_model, adapter_model_path)  # Use base_model here\n",
    "\n",
    "# Step 4: Merge the adapter with the base model and unload the adapter\n",
    "merged_model = adapter_model.merge_and_unload()  # This merges the fine-tuned weights into the base model\n",
    "\n",
    "# Now, `merged_model` contains the final model (base model + fine-tuned adapter).\n",
    "\n",
    "# Optionally save the final merged model\n",
    "merged_model.save_pretrained(\"./final-tagalog-keyboard-model1\")\n",
    "\n",
    "# You can also save the tokenizer if needed\n",
    "tokenizer.save_pretrained(\"./final-tagalog-keyboard-model1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32000, 320, 282, 199, 30055, 32001, 199]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the messages (you can have multiple messages in the list)\n",
    "messages = [\n",
    "    {'role': 'user', 'content': 'Hello'}\n",
    "]\n",
    "\n",
    "# Apply the chat template to the messages\n",
    "formatted_input = tokenizer.apply_chat_template(messages)\n",
    "formatted_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path = \"./final-tagalog-keyboard-model1\"  # Path to the final merged model\n",
    "model = AutoModelForCausalLM.from_pretrained(final_model_path)  # Load the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Ibinigay ang hindi kumpletong pangungusap, magmungkahi ng mga posibleng salita upang kumpletuhin ito:\\n<|user|>\\n    Maglalaro tayo ng b\\n<|assistant|>\\n    Mga mungkahi ng sal: anayin ang mga salita sa mga salita.|||||||||||||||||||||||||||||||||||||||||'}]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Provide a prompt in Tagalog for generating word suggestions\n",
    "prompt = (\n",
    "    \"Ibinigay ang hindi kumpletong pangungusap, magmungkahi ng mga posibleng salita upang kumpletuhin ito:\\n\"\n",
    "    \"<|user|>\\n    Maglalaro tayo ng b\\n<|assistant|>\\n    \"\n",
    "    \"Mga mungkahi ng sal: \"\n",
    ")\n",
    "\n",
    "# Step 4: Generate the next word prediction (with multiple suggestions)\n",
    "result = generator(prompt, max_length=100)  # Adjust max_length as needed\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
