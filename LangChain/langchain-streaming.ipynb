{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882b3177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ec43cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of India is New Delhi.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 14, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BkDbwffFVwSMrJ3E0JiyAF9uvBO5K', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9bd68da7-fedc-4995-a052-ba28972240a2-0', usage_metadata={'input_tokens': 14, 'output_tokens': 8, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "llm.invoke(\"What is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5550bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<async_generator object BaseChatModel.astream at 0x000001667B9F12C0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.astream(\"What is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a42878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|N|LP| stands| for| Natural| Language| Processing|,| which| is| a| sub|field| of| artificial| intelligence| (|AI|)| and| computational| lingu|istics| focused| on| the| interaction| between| computers| and| humans| through| natural| language|.| The| goal| of| NLP| is| to| enable| machines| to| understand|,| interpret|,| generate|,| and| respond| to| human| language| in| a| way| that| is| both| meaningful| and| useful|.\n",
      "\n",
      "|Key| components| of| NLP| include|:\n",
      "\n",
      "|1|.| **|Text| Processing|**|:| In|vol|ves| cleaning| and| preparing| text| data| for| analysis|,| including| token|ization|,| stemming|,| le|mmat|ization|,| and| removing| stop| words|.\n",
      "\n",
      "|2|.| **|Syntax| and| Parsing|**|:| An|aly|zing| the| grammatical| structure| of| sentences| to| understand| relationships| between| words|.\n",
      "\n",
      "|3|.| **|Sem|antics|**|:| Understanding| the| meaning| of| words| and| sentences|,| including| word| sense| dis|ambigu|ation| and| semantic| role| labeling|.\n",
      "\n",
      "|4|.| **|Sent|iment| Analysis|**|:| Determ|ining| the| emotional| tone| behind| a| body| of| text|,| often| used| in| social| media| monitoring| and| customer| feedback| analysis|.\n",
      "\n",
      "|5|.| **|Machine| Translation|**|:| Automatically| translating| text| from| one| language| to| another|.\n",
      "\n",
      "|6|.| **|Speech| Recognition|**|:| Con|verting| spoken| language| into| text|.\n",
      "\n",
      "|7|.| **|Text| Generation|**|:| Creating| coherent| and| context|ually| relevant| text| based| on| input| data|,| as| seen| in| chat|bots| and| content| generation| tools|.\n",
      "\n",
      "|8|.| **|Named| Entity| Recognition| (|NER|)**|:| Ident|ifying| and| class|ifying| key| entities| in| text|,| such| as| names| of| people|,| organizations|,| locations|,| etc|.\n",
      "\n",
      "|N|LP| has| a| wide| range| of| applications|,| including| virtual| assistants| (|like| Siri| and| Alexa|),| chat|bots|,| language| translation| services|,| sentiment| analysis| tools|,| and| more|.| The| field| has| seen| significant| advancements| in| recent| years|,| particularly| with| the| development| of| deep| learning| techniques| and| large| language| models|,| which| have| greatly| improved| the| ability| of| machines| to| understand| and| generate| human| language|.||"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for token in llm.stream(\"What is NLP?\"):\n",
    "    tokens.append(token)\n",
    "    print(token.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02ac1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run--263393ca-3ed1-448a-ac16-a43299c179ea')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea97ee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|N|LP| stands| for| Natural| Language| Processing|,| which| is| a| sub|field| of| artificial| intelligence| (|AI|)| and| computational| lingu|istics|.| It| focuses| on| the| interaction| between| computers| and| humans| through| natural| language|.| The| goal| of| NLP| is| to| enable| machines| to| understand|,| interpret|,| generate|,| and| respond| to| human| language| in| a| way| that| is| both| meaningful| and| useful|.\n",
      "\n",
      "|Key| tasks| and| applications| of| NLP| include|:\n",
      "\n",
      "|1|.| **|Text| Analysis|**|:| Understanding| and| extracting| information| from| text|,| such| as| sentiment| analysis|,| topic| modeling|,| and| summar|ization|.\n",
      "\n",
      "|2|.| **|Machine| Translation|**|:| Automatically| translating| text| from| one| language| to| another|,| as| seen| in| services| like| Google| Translate|.\n",
      "\n",
      "|3|.| **|Speech| Recognition|**|:| Con|verting| spoken| language| into| text|,| which| is| used| in| virtual| assistants| like| Siri| and| Alexa|.\n",
      "\n",
      "|4|.| **|Chat|bots| and| Convers|ational| Agents|**|:| Creating| systems| that| can| engage| in| dialogue| with| users|,| providing| information| or| assistance|.\n",
      "\n",
      "|5|.| **|Information| Retrieval|**|:| Enh|ancing| search| engines| to| better| understand| user| queries| and| retrieve| relevant| information|.\n",
      "\n",
      "|6|.| **|Named| Entity| Recognition| (|NER|)**|:| Ident|ifying| and| class|ifying| key| entities| in| text|,| such| as| names| of| people|,| organizations|,| and| locations|.\n",
      "\n",
      "|7|.| **|Text| Generation|**|:| Produ|cing| coherent| and| context|ually| relevant| text|,| as| seen| in| applications| like| content| creation| and| automated| report| generation|.\n",
      "\n",
      "|N|LP| combines| techniques| from| lingu|istics|,| computer| science|,| and| machine| learning| to| process| and| analyze| large| amounts| of| natural| language| data|.| As| technology| advances|,| NLP| continues| to| improve|,| enabling| more| sophisticated| interactions| between| humans| and| machines|.||"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "async for token in llm.astream(\"What is NLP?\"):\n",
    "    tokens.append(token)\n",
    "    print(token.content, end=\"|\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cacc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x\n",
    "\n",
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`. You MUST use this tool\n",
    "    to conclude the interaction.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaa650b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, multiply, exponentiate, subtract, final_answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0646ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided back to you. You MUST \"\n",
    "        \"then use the final_answer tool to provide a final answer to the user. \"\n",
    "        \"DO NOT use the same tool more than once.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4927dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "# define the agent runnable\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461a3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "# create tool name to function mapping\n",
    "name2tool = {tool.name: tool.func for tool in tools}\n",
    "\n",
    "class CustomAgentExecutor:\n",
    "    chat_history: list[BaseMessage]\n",
    "\n",
    "    def __init__(self, max_iterations: int = 3):\n",
    "        self.chat_history = []\n",
    "        self.max_iterations = max_iterations\n",
    "        self.agent: RunnableSerializable = (\n",
    "            {\n",
    "                \"input\": lambda x: x[\"input\"],\n",
    "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "                \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "            }\n",
    "            | prompt\n",
    "            | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    "        )\n",
    "\n",
    "    def invoke(self, input: str) -> dict:\n",
    "        # invoke the agent but we do this iteratively in a loop until\n",
    "        # reaching a final answer\n",
    "        count = 0\n",
    "        agent_scratchpad = []\n",
    "        while count < self.max_iterations:\n",
    "            # invoke a step for the agent to generate a tool call\n",
    "            out = self.agent.invoke({\n",
    "                \"input\": input,\n",
    "                \"chat_history\": self.chat_history,\n",
    "                \"agent_scratchpad\": agent_scratchpad\n",
    "            })\n",
    "            # if the tool call is the final answer tool, we stop\n",
    "            if out.tool_calls[0][\"name\"] == \"final_answer\":\n",
    "                break\n",
    "            agent_scratchpad.append(out)  # add tool call to scratchpad\n",
    "            # otherwise we execute the tool and add it's output to the agent scratchpad\n",
    "            tool_out = name2tool[out.tool_calls[0][\"name\"]](**out.tool_calls[0][\"args\"])\n",
    "            # add the tool output to the agent scratchpad\n",
    "            action_str = f\"The {out.tool_calls[0]['name']} tool returned {tool_out}\"\n",
    "            agent_scratchpad.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": action_str,\n",
    "                \"tool_call_id\": out.tool_calls[0][\"id\"]\n",
    "            })\n",
    "            # add a print so we can see intermediate steps\n",
    "            print(f\"{count}: {action_str}\")\n",
    "            count += 1\n",
    "        # add the final output to the chat history\n",
    "        final_answer = out.tool_calls[0][\"args\"]\n",
    "        # this is a dictionary, so we convert it to a string for compatibility with\n",
    "        # the chat history\n",
    "        final_answer_str = json.dumps(final_answer)\n",
    "        self.chat_history.append({\"input\": input, \"output\": final_answer_str})\n",
    "        self.chat_history.extend([\n",
    "            HumanMessage(content=input),\n",
    "            AIMessage(content=final_answer_str)\n",
    "        ])\n",
    "        # return the final answer in dict form\n",
    "        return final_answer\n",
    "    \n",
    "agent_executor = CustomAgentExecutor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3cfb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: The add tool returned 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': '10 + 10 equals 20.', 'tools_used': ['functions.add']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(input=\"What is 10 + 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b94cecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84ef5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraphstudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
