{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d01dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0c0b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of India is New Delhi.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 14, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BYzkVYNZz4S3suNZ7B1wEenAIEOhT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4521d3a9-841c-4622-aa4a-83f334d84c8f-0', usage_metadata={'input_tokens': 14, 'output_tokens': 8, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "llm.invoke(\"What is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83726dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "prompt_template = \"Give me a small report on {topic}\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"topic\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d02b1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, Ajit! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 13, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BYzkVwnffiq78YNdQRqaBeuvyKZs2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3cb5d2c7-2915-4b15-a15c-431ba899e7cf-0', usage_metadata={'input_tokens': 13, 'output_tokens': 12, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi My name is Ajit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9af7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8caf3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Ajit! How can I assist you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(\"Hi My name is Ajit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d7afdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajite\\AppData\\Local\\Temp\\ipykernel_29932\\2960353250.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(prompt=prompt, llm=llm, output_parser=output_parser)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(prompt=prompt, llm=llm, output_parser=output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3230496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'retrieval augmented generation',\n",
       " 'text': '### Report on Retrieval-Augmented Generation (RAG)\\n\\n#### Introduction\\nRetrieval-Augmented Generation (RAG) is an innovative approach that combines the strengths of information retrieval and natural language generation. This method enhances the capabilities of language models by allowing them to access external knowledge bases or documents during the generation process, thereby improving the accuracy and relevance of the generated content.\\n\\n#### Key Components\\n1. **Retrieval Mechanism**: RAG employs a retrieval system to fetch relevant documents or pieces of information from a large corpus. This is typically done using techniques such as vector embeddings or traditional keyword-based search methods. The retrieval component ensures that the model has access to up-to-date and contextually relevant information.\\n\\n2. **Generative Model**: After retrieving relevant documents, a generative model (often based on transformer architectures like BERT or GPT) processes this information to produce coherent and contextually appropriate responses. The generative model can leverage the retrieved data to enhance its output, making it more informative and accurate.\\n\\n3. **Integration**: The integration of retrieval and generation is crucial. The generative model is designed to incorporate the retrieved information seamlessly, allowing it to produce responses that are not only fluent but also grounded in factual data.\\n\\n#### Applications\\n- **Question Answering**: RAG is particularly effective in question-answering systems where users seek specific information. By retrieving relevant documents, the model can provide precise answers backed by evidence.\\n- **Chatbots and Virtual Assistants**: In conversational AI, RAG can enhance the quality of interactions by providing responses that are informed by a broader context, improving user satisfaction.\\n- **Content Creation**: RAG can assist in generating articles, reports, or summaries by pulling in relevant data from various sources, ensuring that the content is both comprehensive and accurate.\\n\\n#### Advantages\\n- **Improved Accuracy**: By accessing external knowledge, RAG can produce more factually correct and contextually relevant outputs compared to traditional generative models that rely solely on pre-trained knowledge.\\n- **Dynamic Knowledge Updating**: RAG systems can be updated with new information without retraining the entire model, making them adaptable to changing information landscapes.\\n- **Enhanced Contextual Understanding**: The ability to retrieve and incorporate relevant documents allows for a deeper understanding of context, leading to more nuanced and informed responses.\\n\\n#### Challenges\\n- **Complexity**: The integration of retrieval and generation adds complexity to the system, requiring careful design and tuning to ensure effective performance.\\n- **Latency**: The retrieval process can introduce latency, which may affect the responsiveness of applications, particularly in real-time scenarios.\\n- **Quality of Retrieved Information**: The effectiveness of RAG heavily depends on the quality and relevance of the retrieved documents. Poor retrieval can lead to inaccurate or irrelevant outputs.\\n\\n#### Conclusion\\nRetrieval-Augmented Generation represents a significant advancement in the field of natural language processing, combining the strengths of retrieval systems with generative models to produce more accurate and contextually relevant outputs. As the technology continues to evolve, it holds promise for a wide range of applications, from enhancing conversational agents to improving information retrieval systems. However, addressing the associated challenges will be crucial for its successful implementation in real-world scenarios.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"retrieval augmented generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe92722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'retrieval augmented generation',\n",
       " 'text': '### Report on Retrieval-Augmented Generation (RAG)\\n\\n#### Introduction\\nRetrieval-Augmented Generation (RAG) is an advanced approach in natural language processing (NLP) that combines the strengths of information retrieval and generative models. This technique enhances the capabilities of language models by allowing them to access external knowledge sources, thereby improving the accuracy and relevance of generated responses.\\n\\n#### Concept Overview\\nRAG operates on the principle of augmenting generative models, such as transformers, with a retrieval mechanism. The process typically involves two main components:\\n\\n1. **Retrieval Component**: This part of the system retrieves relevant documents or pieces of information from a large corpus based on a given query. It often employs techniques like dense vector representations and similarity search to find the most pertinent data.\\n\\n2. **Generation Component**: After retrieving relevant information, the generative model uses this data to produce coherent and contextually appropriate responses. This is typically achieved through fine-tuning a pre-trained language model on the retrieved content.\\n\\n#### Mechanism\\nThe RAG framework can be broken down into the following steps:\\n\\n1. **Query Input**: The user provides a query or prompt.\\n2. **Document Retrieval**: The system retrieves a set of relevant documents from a knowledge base or corpus using a retrieval model (e.g., BM25, dense embeddings).\\n3. **Response Generation**: The generative model processes the retrieved documents along with the original query to generate a response that is informed by the external knowledge.\\n\\n#### Advantages\\n- **Enhanced Knowledge Access**: RAG allows models to leverage vast amounts of external information, making them more knowledgeable than standalone generative models.\\n- **Improved Accuracy**: By grounding responses in retrieved documents, RAG can produce more accurate and contextually relevant outputs.\\n- **Dynamic Updates**: The retrieval component can be updated with new information without needing to retrain the entire generative model, allowing for more current responses.\\n\\n#### Applications\\nRAG has a wide range of applications, including:\\n- **Question Answering**: Providing accurate answers to user queries by referencing external documents.\\n- **Chatbots**: Enhancing conversational agents with up-to-date information.\\n- **Content Creation**: Assisting in generating articles or reports that require factual accuracy and depth.\\n\\n#### Challenges\\nDespite its advantages, RAG also faces several challenges:\\n- **Retrieval Quality**: The effectiveness of the system heavily relies on the quality of the retrieved documents.\\n- **Integration Complexity**: Combining retrieval and generation components can be complex and may require careful tuning.\\n- **Latency**: The retrieval process can introduce latency, which may affect user experience in real-time applications.\\n\\n#### Conclusion\\nRetrieval-Augmented Generation represents a significant advancement in the field of NLP, merging the capabilities of information retrieval with generative modeling. By effectively utilizing external knowledge, RAG systems can produce more accurate, relevant, and contextually rich responses, making them valuable tools in various applications. As research and development in this area continue, we can expect further improvements in the efficiency and effectiveness of RAG systems.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"retrieval augmented generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2b6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcel_chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf1cfa4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Report on Retrieval-Augmented Generation (RAG)\\n\\n#### Introduction\\nRetrieval-Augmented Generation (RAG) is an innovative approach that combines the strengths of information retrieval and natural language generation. This method enhances the capabilities of language models by allowing them to access external knowledge bases or documents during the generation process, thereby improving the relevance and accuracy of the generated content.\\n\\n#### Key Concepts\\n1. **Information Retrieval**: RAG utilizes a retrieval mechanism to fetch relevant documents or snippets from a large corpus of text. This step is crucial for providing context and factual information that the language model may not have in its training data.\\n\\n2. **Natural Language Generation**: After retrieving relevant information, a generative model (often based on architectures like Transformers) synthesizes this information into coherent and contextually appropriate responses or narratives.\\n\\n3. **Hybrid Architecture**: RAG typically employs a two-component architecture:\\n   - **Retriever**: This component identifies and retrieves relevant documents based on the input query.\\n   - **Generator**: This component takes the retrieved documents and generates a response that incorporates the information found in those documents.\\n\\n#### Advantages\\n- **Enhanced Accuracy**: By accessing up-to-date and specific information, RAG can produce more accurate and contextually relevant outputs compared to traditional generative models that rely solely on pre-existing knowledge.\\n- **Dynamic Knowledge Integration**: RAG allows models to leverage external knowledge bases, making them adaptable to new information without the need for retraining.\\n- **Improved Contextual Understanding**: The retrieval process helps the model understand the context better, leading to more nuanced and informed responses.\\n\\n#### Applications\\n- **Question Answering**: RAG is particularly effective in applications where users seek specific answers to questions, as it can pull in relevant data from a wide range of sources.\\n- **Content Creation**: In content generation tasks, RAG can provide writers with relevant facts and figures, enhancing the quality and credibility of the output.\\n- **Conversational Agents**: RAG can improve the performance of chatbots and virtual assistants by enabling them to provide more accurate and contextually appropriate responses.\\n\\n#### Challenges\\n- **Retrieval Quality**: The effectiveness of RAG heavily depends on the quality of the retrieval component. Poor retrieval can lead to irrelevant or incorrect information being used in the generation process.\\n- **Computational Complexity**: The dual-component architecture can be more resource-intensive than traditional models, requiring more computational power and time.\\n- **Integration of Retrieved Information**: Ensuring that the generated text seamlessly integrates the retrieved information while maintaining coherence and fluency can be challenging.\\n\\n#### Conclusion\\nRetrieval-Augmented Generation represents a significant advancement in the field of natural language processing, merging the capabilities of information retrieval with generative models. By leveraging external knowledge, RAG enhances the accuracy and relevance of generated content, making it a valuable tool in various applications, from question answering to content creation. As research continues to evolve, addressing the challenges associated with retrieval quality and computational efficiency will be crucial for the broader adoption of RAG in real-world applications.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcel_chain.invoke(\"retrieval augmented generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deaf491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_five(x):\n",
    "    return x+5\n",
    "\n",
    "def sub_five(x):\n",
    "    return x-5\n",
    "\n",
    "def mul_five(x):\n",
    "    return x*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89eb8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "194585c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_five_runnable = RunnableLambda(add_five)\n",
    "sub_five_runnable = RunnableLambda(sub_five)\n",
    "mul_five_runnable = RunnableLambda(mul_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b74ca6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = add_five_runnable | sub_five_runnable | mul_five_runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "788c4eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch.invoke(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f87be260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Give me a small report on {topic}')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1132c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'AI',\n",
       " 'text': '### Report on Artificial Intelligence (AI)\\n\\n#### Introduction\\nArtificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn like humans. It encompasses a variety of technologies and methodologies, including machine learning, natural language processing, robotics, and computer vision. AI has rapidly evolved over the past few decades, becoming an integral part of various industries and daily life.\\n\\n#### Current State of AI\\nAs of 2023, AI technologies are being deployed across numerous sectors, including healthcare, finance, transportation, and entertainment. Key advancements include:\\n\\n1. **Machine Learning (ML)**: Algorithms that enable systems to learn from data and improve over time without explicit programming. Deep learning, a subset of ML, has shown remarkable success in tasks such as image and speech recognition.\\n\\n2. **Natural Language Processing (NLP)**: Technologies that allow machines to understand and respond to human language. Applications include chatbots, virtual assistants, and language translation services.\\n\\n3. **Computer Vision**: The ability of machines to interpret and make decisions based on visual data. This technology is widely used in facial recognition, autonomous vehicles, and medical imaging.\\n\\n4. **Robotics**: AI-driven robots are increasingly used in manufacturing, logistics, and even healthcare, performing tasks ranging from assembly line work to surgical assistance.\\n\\n#### Applications of AI\\n- **Healthcare**: AI is used for diagnostics, personalized medicine, and predictive analytics, improving patient outcomes and operational efficiency.\\n- **Finance**: AI algorithms analyze market trends, detect fraud, and automate trading, enhancing decision-making and risk management.\\n- **Transportation**: Autonomous vehicles leverage AI for navigation and safety, while AI systems optimize traffic management and logistics.\\n- **Entertainment**: Streaming services use AI to recommend content based on user preferences, while video games employ AI for more realistic and adaptive gameplay.\\n\\n#### Challenges and Ethical Considerations\\nDespite its potential, AI poses several challenges:\\n- **Bias and Fairness**: AI systems can perpetuate or exacerbate biases present in training data, leading to unfair outcomes.\\n- **Privacy**: The use of AI in data collection raises concerns about user privacy and data security.\\n- **Job Displacement**: Automation driven by AI may lead to job losses in certain sectors, necessitating workforce retraining and adaptation.\\n- **Regulation**: The rapid development of AI technologies outpaces regulatory frameworks, raising questions about accountability and governance.\\n\\n#### Future Outlook\\nThe future of AI is promising, with ongoing research focused on enhancing capabilities, improving ethical standards, and ensuring responsible deployment. Areas of interest include:\\n- **Explainable AI**: Developing systems that provide transparency in decision-making processes.\\n- **General AI**: Research aimed at creating machines with human-like cognitive abilities.\\n- **AI in Climate Change**: Leveraging AI for environmental monitoring, resource management, and sustainable practices.\\n\\n#### Conclusion\\nAI is transforming industries and society, offering significant benefits while also presenting challenges that require careful consideration. As technology continues to evolve, a balanced approach that prioritizes ethical standards and human welfare will be essential for harnessing the full potential of AI.\\n\\n---\\n\\nThis report provides a snapshot of the current landscape of AI, its applications, challenges, and future directions. For further exploration, ongoing research and developments in AI should be monitored closely.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95501be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fact(x):\n",
    "    if \"\\n\\n\" in x:\n",
    "        return \"\\n\".join(x.split(\"\\n\\n\")[1:])\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "old_word = \"RAG\"\n",
    "new_word = \"hot potato\"\n",
    "\n",
    "def replace_word(x):\n",
    "    return x.replace(old_word, new_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a19d83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_fact_runnable = RunnableLambda(extract_fact)\n",
    "replace_word_runnable = RunnableLambda(replace_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "766e2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser | extract_fact_runnable | replace_word_runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4d099fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Introduction\n",
      "Retrieval-Augmented Generation (hot potato) is an innovative approach that combines the strengths of information retrieval and natural language generation. This method enhances the capabilities of language models by allowing them to access external knowledge bases or documents during the generation process, thereby improving the relevance and accuracy of the generated content.\n",
      "#### Key Components\n",
      "1. **Retrieval Mechanism**: hot potato employs a retrieval system to fetch relevant documents or pieces of information from a large corpus. This can be achieved using various techniques, including traditional keyword-based search, semantic search, or more advanced neural retrieval methods.\n",
      "2. **Generative Model**: After retrieving relevant information, hot potato utilizes a generative model (often based on transformer architectures like BERT or GPT) to synthesize responses. The model incorporates the retrieved information to produce coherent and contextually appropriate text.\n",
      "3. **End-to-End Training**: hot potato models can be trained end-to-end, allowing the retrieval and generation components to learn from each other. This integration helps optimize the retrieval process based on the specific needs of the generation task.\n",
      "#### Advantages\n",
      "- **Enhanced Knowledge Access**: By leveraging external data, hot potato can provide more accurate and contextually rich responses, especially in domains where the model's training data may be limited.\n",
      "- **Dynamic Information**: hot potato can access up-to-date information, making it suitable for applications that require current knowledge, such as news summarization or question answering.\n",
      "- **Improved Contextuality**: The combination of retrieval and generation allows for responses that are more relevant to the user's query, as the model can draw on specific examples or data points.\n",
      "#### Applications\n",
      "- **Question Answering**: hot potato is particularly effective in systems designed to answer user queries by retrieving relevant documents and generating precise answers.\n",
      "- **Chatbots and Virtual Assistants**: These systems can provide more informative and context-aware responses by accessing external knowledge bases.\n",
      "- **Content Creation**: hot potato can assist in generating articles, reports, or summaries by pulling in relevant information from various sources.\n",
      "#### Challenges\n",
      "- **Retrieval Quality**: The effectiveness of hot potato heavily depends on the quality of the retrieval mechanism. Poor retrieval can lead to irrelevant or incorrect information being included in the generated text.\n",
      "- **Computational Complexity**: The integration of retrieval and generation processes can increase the computational load, requiring more resources for training and inference.\n",
      "- **Bias and Misinformation**: If the retrieval corpus contains biased or inaccurate information, the generated outputs may reflect these issues, necessitating careful curation of the data sources.\n",
      "#### Conclusion\n",
      "Retrieval-Augmented Generation represents a significant advancement in the field of natural language processing, merging the capabilities of information retrieval with generative models. By enabling access to external knowledge, hot potato enhances the relevance and accuracy of generated content, making it a powerful tool for various applications. However, challenges related to retrieval quality and computational demands must be addressed to fully realize its potential. As research in this area continues to evolve, hot potato is likely to play an increasingly important role in the development of intelligent systems.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"retrieval augmented generation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb4ee961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6f5e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd9b735b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x000002CA077A68F0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x000002CA15ABDE40>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28301c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajite\\anaconda3\\envs\\langgraphstudy\\lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "vecstore_a = DocArrayInMemorySearch.from_texts(\n",
    "    [\"half the info is here\", \"James' birthday is December the 7th\"], \n",
    "    embedding=embedding\n",
    ")\n",
    "vecstore_b = DocArrayInMemorySearch.from_texts(\n",
    "    [\"the other half of the info is here\", \"James was born in 1994\"], \n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5774a196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\"James' birthday is December the 7th\"),\n",
       " Document(metadata={}, page_content='half the info is here')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecstore_a.similarity_search(\"James' birthday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8c1d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"Using the context provided, answer the user's question.\n",
    "Context: \n",
    "{context_a}\n",
    "{context_b}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26d38d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    " ChatPromptTemplate,\n",
    " SystemMessagePromptTemplate,\n",
    " HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    " SystemMessagePromptTemplate.from_template(prompt_str),\n",
    " HumanMessagePromptTemplate.from_template(\"{question}\") \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca4419a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context_a', 'context_b', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context_a', 'context_b'], input_types={}, partial_variables={}, template=\"Using the context provided, answer the user's question.\\nContext: \\n{context_a}\\n{context_b}\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43bb3093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "retriever_a = vecstore_a.as_retriever()\n",
    "retriever_b = vecstore_b.as_retriever()\n",
    "\n",
    "retrieval = RunnableParallel(\n",
    "    {\n",
    "        \"context_a\": retriever_a, \"context_b\": retriever_b,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6be2a08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context_a: VectorStoreRetriever(tags=['DocArrayInMemorySearch'], vectorstore=<langchain_community.vectorstores.docarray.in_memory.DocArrayInMemorySearch object at 0x000002CA1AB59450>, search_kwargs={}),\n",
       "  context_b: VectorStoreRetriever(tags=['DocArrayInMemorySearch'], vectorstore=<langchain_community.vectorstores.docarray.in_memory.DocArrayInMemorySearch object at 0x000002CA055C29B0>, search_kwargs={}),\n",
       "  question: RunnablePassthrough()\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb45866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = retrieval | prompt | llm | output_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31d7313f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'James was born on December 7, 1994.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chain.invoke(\"What was the date when James was born\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030033b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraphstudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
